\section{Desired inference}

\section{Sketch of the current methodology and validation}
We evaluated the methodology using simulation studies that follow two different schema. Under the first schema, autoregressive processes were simulated for representing linear biological processes in which the correlation between simulated metabolites decreased in tandem with decreasing structural similarity. Under the second schema, random covariance matrices corresponding to structural similarity were simulated using the C-vines method \cite{lewandowski2009}. In this case, a hierarchical model was used, in which structural similarity was simulated first, followed by abundance distributions in which the correlation between abundances increased with structural similarity. Given both schema, we evaluated the ability of the proposed method to recover the true pairwise conditional correlations structures that were specified in advance. We then evaluate our methodology for generating graphical models for representing the relationships between metabolites detected and quantified from human plasma, and specifically for the development of a reference model for stable coronary artery disease.  

\section{Molecular structure priors and the BGL}
We propose that to incorporate prior knowledge regarding the relatedness of compounds, the scale hyperparameter can be linked to structural similarity, that is by specifying the prior distribution $\lambda_{ij}\sim Gamma(r,s_{ij})$ where $s_{ij}$ is a measure of structural similarity between compound $i$ and compound $j$. The conditional expected value of each $\lambda_{ij}$ is then: $\EE(\lambda_{ij}|\Omega)=(1+r)/(|\omega_{ij} |+s_{ij})$.

To generate informative shrinkage priors for the adaptive Bayesian graphical Lasso, we utilized a local structure similarity metric. This metric was adapted from the previously described Chemically Aware Substructure Search (CASS) algorithm \cite{mitchell2014}. In this adaptation, the structural similarity between any two chemical structures (A and B)  was estimated using strings representing local chemical structure (referred to as the atom’s color) centered at every atom in the two structures. The color of every atom was constructed as follows. First, for every bonded atom, its element type and the order of the bond connecting it to the center atom are joined to form a component string that is added to a list of components. For example, if the center atom has a double bonded oxygen, this would contribute a ``O2'' component to the component list. Every component represents a portion of the local bonded structure at the center atom. Second, the components strings are then sorted alphanumerically and concatenated to produce a description of the bonded structure one bond away from the center atom. Finally, to the front of this string, the element type of the center atom is then added to yield the atom’s color. Each color uniquely maps to a single locally bonded structure (e.g. the ``CC1O1O2'' coloring represents a carbon of a carboxylate). Since the component list was first sorted alphanumerically, this color is consistent for all identical local structures regardless of how they are ordered in their representation. Each chemical structure can be represented as the list of its constituent atom’s colors and these lists of colors can be compared to determine structural similarity. To determine structural similarity between compounds using the color string representations, the Tanimoto coefficient between pairs of compounds was computed, which is defined as \cite{chen2002}:
\begin{align}
	s(A,B)=\frac{\sum_{i=1}^m \min \left(n_i(A),n_i(B) \right)}{\sum_{i=1}^m n_i(A)+\sum_{i=1}^m n_i(B)-\sum_{i=1}^m \min \left(n_i(A),n_i(B) \right)}
\end{align}
where $n_i(A)$ represents the count of unique atom pairs indexed by $i=1,2,\hdots,m$ for molecule $A$. The Tanimoto dissimilarity is then $d(A,B)=1-s(A,B)$. 

\begin{figure}[ht]
	\resizebox{1.1\textwidth}{!}{\includegraphics*{../Aim2/Plots/lambdasVsSim}}
	\caption[Structural similarity versus shrinkage]{Theoretical relationship between the structural similarity of two metabolites and the expected value of the shrinkage parameter $\lambda_{ij}$. On the vertical axis...[LOH] \label{fig:simShrink} }
\end{figure}

After determining the Tanimoto dissimilarity between each pair of metabolites, the gamma hyperprior distribution for the shrinkage parameter $\lambda$ can be determined by linking the gamma distribution shape to the dissimilarity, that is by setting $s_{ij}=f(1-d(i,j))$ where $i,j$ index metabolites and $f(x)$ is a monotonic function. The conditional distribution of the shrinkage parameter is then $\lambda_{ij} |\Omega \sim Gamma(1+r,|\omega_{ij} |+s_{ij} )$. A plot of the relationship between the structural similarity of two hypothetical metabolites and the expected value of the shrinkage parameter is shown in  Fig.~\ref{fig:simShrink}. 

To determine a graphical model (or a set of models of high probability) given structural priors samples may be drawn from the posterior distribution of $p(\Omega|X)$, using a Gibb’s sampler as discussed in an earlier chapter and similar to that introduced by Wang \cite{wang2012}. Using a scale mixture of normals representation  \cite{west1987} and introducing the latent scale parameter matrix $\boldsymbol{\tau}$, the unnormalized posterior distribution can be written as \cite{wang2012}: [LOH]
\begin{align}
\begin{split}
	p(\boldsymbol{\Omega}, \boldsymbol{\tau}|\textbf{X}, \boldsymbol{\Lambda}) \propto |\boldsymbol{\Omega}| ^{n/2} \exp \left(-\tr \left(\frac{1}{2}\textbf{S}\boldsymbol{\Omega} \right) \right)\\ \prod_{i<j} \left(\tau_{ij}^{-1/2} \exp \left(-\omega_{ij}^2 / (2\tau_{ij}) \right) \exp \left(-\frac{1}{2} \lambda_{ij}^2 \tau_{ij}\right)\right)  \prod_{i=1}^{p} \exp(-\frac{1}{2} \lambda_{ij} \omega_{ij}) 1_{\boldsymbol{\Omega}\in M^+}
\end{split}
\end{align}

The block Gibb’s sampler cycles through column-wise partitions of $\boldsymbol{\Omega}$, drawing from the conditional distribution of a single column of the matrix $\boldsymbol{\Omega}$, conditioned on the current values of the remaining columns.

\section{R package development} [LOH]
 We developed an R package, \emph{BayesianGLasso}, for implementing this and other samplers for the Bayesian Graphical Lasso. The underlying sampler was written in C++ using Rcpp and RcppArmadillo to make use of the Armadillo linear algebra library. In addition to providing Gibb’s sampling methods the R package developed by our group includes classes for storing the Markov chains generated by the sampler along with relevant parameters and hyperparameters, and methods for conducting statistical inference over the simulated posterior distributions.

\section{Efficacy analysis via simulation studies}
To evaluate the efficacy of the proposed method, we employed simulation studies. We sought to evaluate the relative performance of the adaptive Bayesian Graphical Lasso (BGL) using informative priors versus (1) the adaptive Bayesian Graphical Lasso using non-informative priors, and (2) the Bayesian Graphical Lasso (non-adaptive). For the informative prior case, we further manipulated the degree to which the priors were accurate relative to the partial correlation structure utilized to generate the data. We evaluated the methods by simulating both simple partial correlation structures as well as more complex structures utilizing two simulation schemas. Under the first schema, a simple autoregressive (AR) process of order 1 was simulated for representing a linear biological process with decreasing structural similarity with increasing process distance. Simulated structural similarity was taken to be deterministically known, that is a structural similarity matrix was defined as: $\boldsymbol{\Sigma} = \left[\sigma_{ij}\right]$ where $\sigma_{ij}=\rho^{|i-j|}$ . To simulate metabolite abundances, a random matrix was sampled from the multivariate normal distribution $N(\textbf{0},\boldsymbol{\Sigma})$. In the “accurate” informative prior case, the shrinkage hyperprior $s_{ij}$ was defined as $s_{ij}$=$\omega_{ij}^{-1}$, where $\omega_{ij}^{-1}$ are the elements of $\boldsymbol{\Omega}=\boldsymbol{\Sigma}^{-1}$. After generating simulated datasets, the adaptive BGL (with informative and non-informative priors) as well as the non-adaptive BGL were utilized for estimating the concentration matrix and corresponding graph topology. Given the simple dependence structure in the AR(1) case, a measure of ground truth was available as the existence of edges between simulated metabolites was known a priori. We evaluated the sensitivity, specificity, and $F_1$ measure of each method for detecting the presence of edges by utilizing the magnitude of the estimated concentration matrix entries: $|\omega_{ij}|$. In addition, we report the area under the receiver operating characteristic curve for assessing each technique, which considers the range of possible fixed cutoff values of $|\omega_{ij}|$ for estimating the presence or absence of edges. While each technique draws shrinkage parameters from a Gamma distribution, the shape and scale of each distribution depends both on empirical data and hyperparameters. We conducted shape and scale hyperparameter optimization separately for each technique via a grid search over simulated datasets prior to the evaluation of performance.

\section{Results of the simulation studies}
Results from the simulation studies given an autoregressive covariance structure are shown in Table 1 and Figures~\ref{fig:ar1}-\ref{fig:ar1res}. In Figure~\ref{fig:ar1} a graphical model representation of the underlying covariance structure is shown along with the graphical model representations of the sample covariance matrix and the concentration matrices estimated by the multiple techniques evaluated in this study. These figures were generated from a randomly sampled simulation study. 

\newpage
\KOMAoptions{paper=landscape}
\recalctypearea
\begin{figure}[h!]
\includegraphics[scale=.6]{../Aim2/Plots/AR1}
	\caption[AR(1) Simulation]{True and estimated concentration matrix graphs for a randomly selected AR(1) simulation study with $p=20$ simulated random variates (metabolites) and a simulated sample size of $n=10$. Graphs represent the: (a) true concentration structure given an AR(1) covariance structure with $\rho=0.95$, (b) sample covariance matrix, (c) concentration matrix estimated by the non-adaptive BGL, (d) concentration matrix estimated by the adaptive BGL with non-informative priors, (e) concentration matrix estimated by the adaptive BGL with chemical structure informative priors.  \label{fig:ar1} }
\end{figure}
\newpage
\KOMAoptions{paper=portrait,pagesize}
\recalctypearea

Results of the simulation studies for the autoregressive case are shown in Figure~\ref{fig:ar1res} with numerical summaries provided in Table~\ref{tab:ar1resTab}. GGM estimation by the Bayesian Graphical Lasso (BGL) and Adaptive BGL exhibited similar performance characteristics with respect to sensitivity, specificity, AUC, and $F_1$ measure. The performance of the chemical structure informative adaptive BGL varied significantly based on the suitability of the informative prior distribution for shrinkage parameters. In the “good prior” case in which it is assumed that the structural similarity and data generating process were deterministically linked, the structure adaptive BGL demonstrated significantly higher sensitivity, specificity, AUC, and $F_1$ measure than the other techniques. Conversely, in the “poor prior” case in which the relationship between the simulated structural similarity and the data generating process was masked by gaussian noise, average AUC and $F_1$ measure were significantly lower for the structure adaptive BGL than the remaining techniques. 

\begin{table}[h!]
	\caption[AR(1) Results Table]{Results of the AR(1) simulation studies. For each of the compared techniques, sensitivity, specificity, area under the receiver operating characteristic curve (AUC), and F1 measure are reported. Reported values represent the sample mean and standard deviation over the simulation study replicates\label{tab:ar1resTab} }
	\begin{center}
		\begin{tabular}{| p{4cm}|c c c c |}
			\hline
			\textbf{Technique} &	\textbf{Sensitivity}	& \textbf{Specificity} &	\textbf{AUC} &	$\textbf{F}_1$ \textbf{Measure} \\
			\hline  \hline
			Bayesian Graphical Lasso (BGL)	& $0.6792 \pm 0.073$ & $0.9896 \pm 0.007$	& $0.9740 \pm 0.014$	& $0.7786 \pm 0.054$ \\
			\hline
			Adaptive BGL &	$0.6702  \pm 0.079$	& $0.9936  \pm 0.006$ &	$0.9793  \pm 0.014$ &	$0.7827  \pm 0.062$\\
			\hline
Chemical Structure Adaptive BGL (Good prior) &	$0.9894 \pm 0.019$ &	$0.9997 \pm 0.001$ &	$1.000 \pm 0.000$ &	$0.9938 \pm 0.011$ \\
\hline
Chemical Structure Adaptive BGL (Poor prior)	&$0.8175 \pm 0.068$	& $0.8763 \pm 0.033$ &	$0.9148 \pm 0.036$ & 	$0.6448 \pm 0.066$ \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

\newpage
\KOMAoptions{paper=landscape}
\recalctypearea
\begin{figure}[h!]
	\resizebox{\textwidth}{!}{\includegraphics*{../Aim2/Plots/AR1Result}}
	\caption[AR(1) Results]{Results of the AR(1) simulation studies. The comparative performance of the techniques (as the ability to detect an edge, given an edge is truly present) is presented. Subfigure (a) shows a histogram of the observed area under the receiver operating characteristic curve (AUC) values, while (b) shows the F1 measure.  \label{fig:ar1res} }
\end{figure}
\newpage
\KOMAoptions{paper=portrait,pagesize}
\recalctypearea